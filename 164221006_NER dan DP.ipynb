{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TUGAS M5 NATURAL LANGUAGE PROCESSING**\n",
    "\n",
    "**NAMED ENTITY RECOGNITION DAN DEPENDENCY PARSER**\n",
    "\n",
    "**DENGAN NLTK DAN SPACY**\n",
    "\n",
    "Nama : Nadila Fitri Noviardhana\n",
    "\n",
    "NIM : 164221006\n",
    "\n",
    "Kelas : NLP SD-A2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER DENGAN NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (GPE Jeno/NNP)\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  member/NN\n",
      "  of/IN\n",
      "  the/DT\n",
      "  (LOCATION South/JJ Korean/JJ)\n",
      "  boy/NN\n",
      "  group/NN\n",
      "  (ORGANIZATION NCT/NNP)\n",
      "  and/CC\n",
      "  is/VBZ\n",
      "  the/DT\n",
      "  lead/JJ\n",
      "  dancer/NN\n",
      "  ,/,\n",
      "  lead/JJ\n",
      "  rapper/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  visual/JJ\n",
      "  of/IN\n",
      "  its/PRP$\n",
      "  sub-unit/JJ\n",
      "  (ORGANIZATION NCT/NNP Dream/NNP))\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "sentence = \"Jeno is a member of the South Korean boy group NCT and is the lead dancer, lead rapper, and visual of its sub-unit NCT Dream\"\n",
    "\n",
    "words = nltk.word_tokenize(sentence)\n",
    "\n",
    "pos_tags = nltk.pos_tag(words)\n",
    "\n",
    "named_entities = nltk.ne_chunk(pos_tags)\n",
    "\n",
    "print(named_entities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hasil dan Identifikasi Kesalahan\n",
    "\n",
    "Hasil dari proses NER di atas menunjukkan beberapa hal berikut.\n",
    "1. Jeno diidentifikasi sebagai GPE atau Lokasi, di mana seharusnya Jeno adalah Person.\n",
    "2. South Korean dilabelkan sebagai LOCATION.\n",
    "3. NCT dan NCT Dream dideteksi sebagai sebuah organisasi.\n",
    "\n",
    "Hasil di atas menunjukkan bahwa NLTK kerap salah dalam mengidentifikasi PERSON. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER dengan Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeno PERSON\n",
      "South Korean NORP\n",
      "NCT ORG\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "sentence = \"Jeno is a member of the South Korean boy group NCT and is the lead dancer, lead rapper, and visual of its sub-unit NCT Dream\"\n",
    "\n",
    "doc = nlp(sentence)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hasil dan Identifikasi Kesalahan Spacy\n",
    "\n",
    "Dari hasil spaCy tersebut, didapatkan beberapa hal berikut.\n",
    "\n",
    "1. Jeno iidentifikasi sebagai PERSON, yaitu nama individu.\n",
    "2. South Korean diidentifikasi sebagai NORP (Nationalities, Religious, or Political groups), yaitu kelompok kebangsaan.\n",
    "3. NCT diidentifikasi sebagai ORG (organization), yaitu sebuah organisasi (dalam hal ini, grup musik).\n",
    "\n",
    "Secara keseluruhan hasil identifikasi sudah tepat dan sesuai konteksnya. Namun masih belum bisa mendeteksi NCT DREAM yang seharusnya sebagai ORG juga."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DP dengan NLTK\n",
    "\n",
    "DP dengan NLTK harus menggunakan tambahan library lagi yaitu Stanford Core NLP. Dalam penggunaan yang saya lakukan masih mengalami kegagalan dan tidak dapat tersambung. \n",
    "Maka kode di bawah ini memang error dan masih tidak dapat di run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-53a5426298d9>:8: DeprecationWarning: The StanfordDependencyParser will be deprecated\n",
      "Please use \u001b[91mnltk.parse.corenlp.CoreNLPDependencyParser\u001b[0m instead.\n",
      "  dependency_parser = StanfordDependencyParser(model_path=\"edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz\")\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n\n===========================================================================\n  NLTK was unable to find stanford-parser\\.jar! Set the CLASSPATH\n  environment variable.\n\n  For more information, on stanford-parser\\.jar, see:\n    <https://nlp.stanford.edu/software/lex-parser.shtml>\n===========================================================================",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTANFORD_MODELS\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstanford-parser-4.2.0-models.jar\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      7\u001b[0m path_to_models_jar \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstanford-parser-4.2.0-models.jar\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 8\u001b[0m dependency_parser \u001b[38;5;241m=\u001b[39m \u001b[43mStanfordDependencyParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43medu/stanford/nlp/models/lexparser/englishPCFG.ser.gz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI eat 2 slices of mango.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m result \u001b[38;5;241m=\u001b[39m dependency_parser\u001b[38;5;241m.\u001b[39mraw_parse(sentence)\n",
      "File \u001b[1;32mc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\parse\\stanford.py:399\u001b[0m, in \u001b[0;36mStanfordDependencyParser.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    392\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    393\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe StanfordDependencyParser will be deprecated\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    394\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use \u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[91mnltk.parse.corenlp.CoreNLPDependencyParser\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[0m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    395\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[0;32m    396\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    397\u001b[0m     )\n\u001b[1;32m--> 399\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\parse\\stanford.py:49\u001b[0m, in \u001b[0;36mGenericStanfordParser.__init__\u001b[1;34m(self, path_to_jar, path_to_models_jar, model_path, encoding, verbose, java_options, corenlp_options)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     40\u001b[0m     path_to_jar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m ):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m# find the most recent code and model jar\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m     stanford_jar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfind_jar_iter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_JAR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpath_to_jar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m            \u001b[49m\u001b[43menv_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSTANFORD_PARSER\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSTANFORD_CORENLP\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m            \u001b[49m\u001b[43msearchpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_stanford_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_regex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdirname\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m     model_jar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\n\u001b[0;32m     63\u001b[0m         find_jar_iter(\n\u001b[0;32m     64\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_MODEL_JAR_PATTERN,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m         key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m model_path: os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(model_path),\n\u001b[0;32m     73\u001b[0m     )\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;66;03m# self._classpath = (stanford_jar, model_jar)\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \n\u001b[0;32m     77\u001b[0m     \u001b[38;5;66;03m# Adding logging jar files to classpath\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\internals.py:823\u001b[0m, in \u001b[0;36mfind_jar_iter\u001b[1;34m(name_pattern, path_to_jar, env_vars, searchpath, url, verbose, is_regex)\u001b[0m\n\u001b[0;32m    818\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  For more information, on \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, see:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    <\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    819\u001b[0m         name_pattern,\n\u001b[0;32m    820\u001b[0m         url,\n\u001b[0;32m    821\u001b[0m     )\n\u001b[0;32m    822\u001b[0m div \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m75\u001b[39m\n\u001b[1;32m--> 823\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdiv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdiv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n\n===========================================================================\n  NLTK was unable to find stanford-parser\\.jar! Set the CLASSPATH\n  environment variable.\n\n  For more information, on stanford-parser\\.jar, see:\n    <https://nlp.stanford.edu/software/lex-parser.shtml>\n==========================================================================="
     ]
    }
   ],
   "source": [
    "import os\n",
    "from nltk.parse.stanford import StanfordDependencyParser\n",
    "\n",
    "os.environ['STANFORD_PARSER'] = 'stanford-parser.jar'\n",
    "os.environ['STANFORD_MODELS'] = 'stanford-parser-4.2.0-models.jar'\n",
    "\n",
    "path_to_models_jar = 'stanford-parser-4.2.0-models.jar'\n",
    "dependency_parser = StanfordDependencyParser(model_path=\"edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz\")\n",
    "\n",
    "sentence = \"I eat 2 slices of mango.\"\n",
    "\n",
    "result = dependency_parser.raw_parse(sentence)\n",
    "\n",
    "# Menampilkan hasil parsing\n",
    "dep = next(result)\n",
    "print(list(dep.triples()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DP dengan Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hubungan antara kata-kata dalam kalimat:\n",
      "i (nsubj) -> eat\n",
      "eat (ROOT) -> eat\n",
      "2 (nummod) -> slices\n",
      "slices (dobj) -> eat\n",
      "of (prep) -> slices\n",
      "mango (pobj) -> of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\displacy\\__init__.py:106: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
      "  warnings.warn(Warnings.W011)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"80a82c4f8c9a498187db9be3767fdc92-0\" class=\"displacy\" width=\"1100\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">i</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">eat</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">2</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">slices</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">mango</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-80a82c4f8c9a498187db9be3767fdc92-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-80a82c4f8c9a498187db9be3767fdc92-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-80a82c4f8c9a498187db9be3767fdc92-0-1\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-80a82c4f8c9a498187db9be3767fdc92-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-80a82c4f8c9a498187db9be3767fdc92-0-2\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-80a82c4f8c9a498187db9be3767fdc92-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M575.0,179.0 L583.0,167.0 567.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-80a82c4f8c9a498187db9be3767fdc92-0-3\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-80a82c4f8c9a498187db9be3767fdc92-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,179.0 L753.0,167.0 737.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-80a82c4f8c9a498187db9be3767fdc92-0-4\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-80a82c4f8c9a498187db9be3767fdc92-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M920.0,179.0 L928.0,167.0 912.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'dep' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "sentence = \"i eat 2 slices of mango\"\n",
    "\n",
    "doc = nlp(sentence)\n",
    "\n",
    "print(\"Hubungan antara kata-kata dalam kalimat:\")\n",
    "for token in doc:\n",
    "    print(f'{token.text} ({token.dep_}) -> {token.head.text}')\n",
    "\n",
    "displacy.serve(doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penjelasan\n",
    "\n",
    "-\t\"i (nsubj) -> eat\": \"I\" adalah subjek dari \"eat\"\n",
    "-\t\"eat (ROOT) -> eat\": \"eat\" adalah kata kerja utama dari kalimat.\n",
    "-\t\"2 (nummod) -> slices\": \"2\" menjelaskan jumlah dari \"slices\".\n",
    "-\t\"slices (dobj) -> eat\": \"slices\" adalah objek langsung dari \"eat\".\n",
    "-\tof (prep) -> slices\": \"of\" menghubungkan \"slices\" dengan \"mango\".\n",
    "-\tmango (pobj) -> of\": \"mango\" adalah objek dari preposisi \"of\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kelebihan dan Kekurangan NLTK dan SpaCy\n",
    "\n",
    "| **Kelebihan**                                      | **Kekurangan**                                       |\n",
    "|----------------------------------------------------|-----------------------------------------------------|\n",
    "| **NLTK**                                            |                                                     |\n",
    "| a. NLTK lebih sederhana untuk proses pembelajaran, namun memberikan hasil yang lebih menyeluruh. | a. Dalam Named Entity Recognition (NER), NLTK kurang akurat dalam mengidentifikasi kategori PERSON. |\n",
    "| b. Lebih fleksibel dalam penyesuaian dan modifikasi sesuai kebutuhan proyek. | b. Cukup lambat ketika digunakan pada dokumen berukuran besar. |\n",
    "| **spaCy**                                           |                                                     |\n",
    "| a. Lebih akurat dalam mengidentifikasi kata, terutama untuk NER. | a. Tidak menampilkan hasil secara menyeluruh untuk NER (hasilnya lebih spesifik). |\n",
    "| b. Tidak memerlukan banyak proses tambahan dalam konfigurasi awal. | b. Modelnya terbatas pada bahasa yang lebih sedikit. |\n",
    "| c. Hasil lebih sederhana, to the point, dan lebih mudah dipahami. |                                                     |\n",
    "| d. Lebih cepat saat digunakan untuk dokumen berukuran besar. |                                                     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perbedaan NLTK dan SpaCy secara umum\n",
    "\n",
    "-\tUntuk melakukan NER maupun DP, NLTK memerlukan proses tambahan yakni Tokenisasi untuk memecah kalimat menjadi tiap token dan Pos Tagging untuk mengidentifikasi tiap kata masuk ke dalam jenis kata apa. Sedangkan SpaCy dapat melakukannya secara langsung tanpa Pos Tagging atau tambahan lainnya.\n",
    "-\tHasil yang didapatkan dari NLTK sangat lengkap dan menyeluruh disertai pula dengan hasil Pos Taggingnya, sedangkan SpaCy hanya terfokus pad NER saja.\n",
    "-\tHasil NER dari SpaCy lebih akurat daripada NLTK."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
